{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 13:24:37.293684: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from data.generator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 10 graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1270.46it/s]\n",
      "Processing...\n",
      "100%|██████████| 10/10 [00:00<00:00, 437.01it/s]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "n = 6\n",
    "p = 0.3\n",
    "\n",
    "dataset = RandomGraphDataset(root='./data', gen_num_graph=10, n=n, p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch.nn import Linear\n",
    "\n",
    "class MPNN(MessagePassing):\n",
    "  def __init__(self, in_channels, hidden_channels, activation=None):\n",
    "    super(MPNN, self).__init__(aggr='max') #  \"Max\" aggregation.\n",
    "    self.in_channels = in_channels\n",
    "    self.hidden_channels = hidden_channels\n",
    "    self.messages = Linear(self.in_channels * 2, self.hidden_channels)\n",
    "    self.update_fn = Linear(self.in_channels + self.hidden_channels, self.hidden_channels)\n",
    "    self.activation = activation\n",
    "\n",
    "    self.mlp = torch.nn.Sequential(\n",
    "        Linear(in_channels, hidden_channels),\n",
    "        torch.nn.ReLU(),\n",
    "        Linear(hidden_channels, hidden_channels)\n",
    "    )\n",
    "    \n",
    "  def forward(self, x, edge_index):\n",
    "    out = self.propagate(edge_index, x=x)\n",
    "    out = self.mlp(out)\n",
    "    if self.activation is not None:\n",
    "      out = self.activation(out)\n",
    "    return out\n",
    "    \n",
    "  def message(self, x_i, x_j):\n",
    "    # x_i has shape [E, in_channels]\n",
    "    # x_j has shape [E, in_channels]\n",
    "    #print('MPNN => xi, xj', x_i.size(), x_j.size())\n",
    "    tmp = torch.cat([x_i, x_j], dim=1)  # tmp has shape [E, 2 * in_channels]\n",
    "    #print('MPNN => messages IN', tmp.size())\n",
    "    m = self.messages(tmp)\n",
    "    #print('MPNN => messages OUT', m.size())\n",
    "    return m\n",
    "  \n",
    "  def update(self, aggr_out, x):\n",
    "    # aggr_out has shape [N, out_channels]\n",
    "    # x has shape [N, in_channels]\n",
    "    #print(f'MPNN => x_i', x.size(), ' aggr_out ', aggr_out.size())\n",
    "    tmp = torch.cat([x, aggr_out], dim=1)\n",
    "    #print(f'MPNN => tmp', tmp.size())\n",
    "    return self.update_fn(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an encoder class\n",
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lin = nn.Linear(1, hidden_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 1:\n",
    "            x = x.unsqueeze(-1)\n",
    "        return self.lin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.lin = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.functional import F\n",
    "class Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Loss, self).__init__()\n",
    "\n",
    "    def forward(self, x: torch.Tensor, x_pred: torch.Tensor, h: torch.Tensor, h_pred: torch.Tensor):\n",
    "        \"\"\"\n",
    "        x: true output value\n",
    "        x_pred: predicted output value\n",
    "        h: true hint values\n",
    "        h_pred: predicted hint values\n",
    "        \"\"\"\n",
    "\n",
    "        loss_x = F.binary_cross_entropy(x, x_pred) # binary cross entropy loss between true and predicted output\n",
    "        hints_loss = 0\n",
    "        for i in range(h.size(1)):\n",
    "            hints_loss += F.binary_cross_entropy(h[:, i], h_pred[:, i])\n",
    "\n",
    "        return loss_x + hints_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.functional import F\n",
    "class Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Loss, self).__init__()\n",
    "\n",
    "    def forward(self, batch, batch_pred: torch.Tensor):\n",
    "\n",
    "        # for every batch find the predicted and true values and send them to the calculate_loss function\n",
    "        loss_x = 0\n",
    "        loss_h = 0\n",
    "        for i in range(batch.len()):\n",
    "            data = batch[i]\n",
    "            x = data.reach_h[-1] # true output value\n",
    "            x_pred = batch_pred[i][-1] # predicted output value\n",
    "            h_pred = batch_pred[i][:-2] # predicted hint values\n",
    "            h = data.reach_h[:len(h_pred)] # true hint values\n",
    "            print(x)\n",
    "            print(x_pred)\n",
    "            loss_x += F.binary_cross_entropy(x, x_pred)\n",
    "            print(loss_x)\n",
    "            for i in range(h.size(1)):\n",
    "                loss_h += F.binary_cross_entropy(h[:, i], h_pred[:, i])\n",
    "\n",
    "        return loss_x + loss_h\n",
    "\n",
    "    \n",
    "    # def calculate_loss(self, x, x_pred, h, h_pred):\n",
    "    #     \"\"\"\n",
    "    #     x: true output value\n",
    "    #     x_pred: predicted output value\n",
    "    #     h: true hint values\n",
    "    #     h_pred: predicted hint values\n",
    "    #     \"\"\"\n",
    "    #     loss_x = F.binary_cross_entropy(x, x_pred) # binary cross entropy loss between true and predicted output\n",
    "    #     hints_loss = 0\n",
    "    #     for i in range(h.size(1)):\n",
    "    #         hints_loss += F.binary_cross_entropy(h[:, i], h_pred[:, i])\n",
    "\n",
    "    #     return loss_x + hints_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i in np.arange(dataset.len()):\n",
    "    data = dataset[i]\n",
    "    predictions.append(data.reach_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([0.7143, 0.1741, 0.1920, 0.8777, 0.7658, 0.3378]),\n",
       "  tensor([0.9543, 0.3689, 0.3727, 0.8353, 0.5775, 0.6603]),\n",
       "  tensor([0.2558, 0.1154, 0.5615, 0.4870, 0.9528, 0.1437]),\n",
       "  tensor([0.3564, 0.6232, 0.4392, 0.9562, 0.7816, 0.5164]),\n",
       "  tensor([0.1900, 0.4127, 0.0310, 0.2288, 0.3915, 0.8450]),\n",
       "  tensor([0.5902, 0.5273, 0.9557, 0.9079, 0.9055, 0.9465])],\n",
       " [tensor([0.9952, 0.3400, 0.4219, 0.8635, 0.0802, 0.3195]),\n",
       "  tensor([0.1953, 0.2896, 0.1495, 0.2523, 0.5475, 0.4005]),\n",
       "  tensor([0.9543, 0.6819, 0.0392, 0.5422, 0.2216, 0.6485]),\n",
       "  tensor([0.7830, 0.5166, 0.4493, 0.7869, 0.9324, 0.0452]),\n",
       "  tensor([0.0222, 0.3534, 0.2351, 0.8061, 0.3082, 0.0164]),\n",
       "  tensor([0.5317, 0.8365, 0.4253, 0.3484, 0.1533, 0.9588])],\n",
       " [tensor([0.2869, 0.0196, 0.1265, 0.4460, 0.2904, 0.4743]),\n",
       "  tensor([4.9248e-01, 3.2627e-01, 3.0349e-01, 6.0767e-04, 6.8539e-01, 5.2193e-01]),\n",
       "  tensor([0.1412, 0.8722, 0.7867, 0.8790, 0.2798, 0.1149]),\n",
       "  tensor([0.4754, 0.3637, 0.7234, 0.7863, 0.5685, 0.8254]),\n",
       "  tensor([0.0062, 0.8412, 0.8382, 0.3699, 0.1547, 0.5254]),\n",
       "  tensor([0.9035, 0.0094, 0.9067, 0.8229, 0.9845, 0.7472])],\n",
       " [tensor([0.9030, 0.1505, 0.5034, 0.4106, 0.3040, 0.2303]),\n",
       "  tensor([0.9632, 0.6148, 0.9349, 0.0138, 0.9778, 0.8629]),\n",
       "  tensor([0.1904, 0.6257, 0.9402, 0.7634, 0.0953, 0.4600]),\n",
       "  tensor([0.8357, 0.2279, 0.9459, 0.4253, 0.0292, 0.7662]),\n",
       "  tensor([0.6991, 0.4273, 0.9817, 0.8426, 0.5975, 0.6964]),\n",
       "  tensor([0.3609, 0.0586, 0.4814, 0.5126, 0.3529, 0.5083])],\n",
       " [tensor([0.1713, 0.6223, 0.4513, 0.4632, 0.5577, 0.4460]),\n",
       "  tensor([0.6282, 0.8259, 0.0427, 0.6136, 0.6671, 0.4271]),\n",
       "  tensor([0.9628, 0.9683, 0.3105, 0.7383, 0.8407, 0.6086]),\n",
       "  tensor([0.9657, 0.6303, 0.5311, 0.9091, 0.5843, 0.3391]),\n",
       "  tensor([0.8587, 0.4638, 0.2035, 0.6633, 0.6496, 0.8490]),\n",
       "  tensor([0.2441, 0.1334, 0.6711, 0.1318, 0.5126, 0.4870])],\n",
       " [tensor([0.2478, 0.0085, 0.5248, 0.9021, 0.7361, 0.0111]),\n",
       "  tensor([0.5787, 0.6420, 0.2752, 0.0249, 0.3805, 0.1888]),\n",
       "  tensor([0.6740, 0.9983, 0.1017, 0.5007, 0.6134, 0.5624]),\n",
       "  tensor([0.5152, 0.4620, 0.5967, 0.1404, 0.2163, 0.7114]),\n",
       "  tensor([0.2883, 0.0253, 0.7597, 0.9138, 0.3671, 0.9580]),\n",
       "  tensor([0.5789, 0.5226, 0.5994, 0.9133, 0.2846, 0.1763])],\n",
       " [tensor([0.6071, 0.2622, 0.4516, 0.9773, 0.3208, 0.7172]),\n",
       "  tensor([0.0819, 0.9402, 0.7677, 0.3318, 0.3737, 0.6529]),\n",
       "  tensor([0.2138, 0.5603, 0.5888, 0.2838, 0.9457, 0.4037]),\n",
       "  tensor([0.8327, 0.9500, 0.0172, 0.4679, 0.7153, 0.8768]),\n",
       "  tensor([0.3002, 0.1265, 0.7470, 0.5462, 0.8274, 0.1149]),\n",
       "  tensor([0.5658, 0.7260, 0.6368, 0.5657, 0.0154, 0.6297])],\n",
       " [tensor([0.3220, 0.9842, 0.6733, 0.2283, 0.3414, 0.4019]),\n",
       "  tensor([0.0274, 0.9183, 0.3082, 0.1607, 0.8772, 0.8560]),\n",
       "  tensor([0.2832, 0.8702, 0.6694, 0.0685, 0.3797, 0.7964]),\n",
       "  tensor([0.0861, 0.2688, 0.5217, 0.4847, 0.0955, 0.7617]),\n",
       "  tensor([0.6282, 0.0159, 0.9551, 0.3957, 0.8291, 0.8349]),\n",
       "  tensor([0.5717, 0.7269, 0.5213, 0.8912, 0.5953, 0.1764])],\n",
       " [tensor([0.9431, 0.4618, 0.0998, 0.2881, 0.2831, 0.9303]),\n",
       "  tensor([0.9871, 0.0514, 0.9292, 0.1869, 0.9637, 0.8706]),\n",
       "  tensor([0.4728, 0.8676, 0.8844, 0.3168, 0.4005, 0.6185]),\n",
       "  tensor([0.0879, 0.1133, 0.7718, 0.9147, 0.8616, 0.8001]),\n",
       "  tensor([0.0958, 0.2687, 0.5859, 0.3186, 0.2157, 0.3681]),\n",
       "  tensor([0.5666, 0.8294, 0.8434, 0.5645, 0.4640, 0.7891])],\n",
       " [tensor([0.4491, 0.0345, 0.6444, 0.8035, 0.1718, 0.4730]),\n",
       "  tensor([0.4946, 0.7516, 0.4868, 0.3068, 0.6850, 0.1581]),\n",
       "  tensor([0.0705, 0.6895, 0.5757, 0.4398, 0.9241, 0.7176]),\n",
       "  tensor([0.1457, 0.8207, 0.1117, 0.4973, 0.1224, 0.9280]),\n",
       "  tensor([0.9510, 0.3493, 0.6833, 0.3888, 0.7177, 0.6601]),\n",
       "  tensor([0.3050, 0.9240, 0.3982, 0.4474, 0.1774, 0.7847])]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = []\n",
    "for d in dataset:\n",
    "    h_pred = []\n",
    "    # generate a prediction wich is the same size as the reach_h\n",
    "    len = d.reach_h[-1].size(0)\n",
    "    hints_len = d.reach_h.size(1)\n",
    "    # create as many predictions as there are hints\n",
    "    for i in range(hints_len):\n",
    "        h_pred.append(torch.rand(len))\n",
    "    # append the prediction to the list\n",
    "    predictions.append(h_pred)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "preditions = []\n",
    "\n",
    "for d in dataset:\n",
    "    predictions.append(d.reach_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([0.7143, 0.1741, 0.1920, 0.8777, 0.7658, 0.3378]),\n",
       "  tensor([0.9543, 0.3689, 0.3727, 0.8353, 0.5775, 0.6603]),\n",
       "  tensor([0.2558, 0.1154, 0.5615, 0.4870, 0.9528, 0.1437]),\n",
       "  tensor([0.3564, 0.6232, 0.4392, 0.9562, 0.7816, 0.5164]),\n",
       "  tensor([0.1900, 0.4127, 0.0310, 0.2288, 0.3915, 0.8450]),\n",
       "  tensor([0.5902, 0.5273, 0.9557, 0.9079, 0.9055, 0.9465])],\n",
       " [tensor([0.9952, 0.3400, 0.4219, 0.8635, 0.0802, 0.3195]),\n",
       "  tensor([0.1953, 0.2896, 0.1495, 0.2523, 0.5475, 0.4005]),\n",
       "  tensor([0.9543, 0.6819, 0.0392, 0.5422, 0.2216, 0.6485]),\n",
       "  tensor([0.7830, 0.5166, 0.4493, 0.7869, 0.9324, 0.0452]),\n",
       "  tensor([0.0222, 0.3534, 0.2351, 0.8061, 0.3082, 0.0164]),\n",
       "  tensor([0.5317, 0.8365, 0.4253, 0.3484, 0.1533, 0.9588])],\n",
       " [tensor([0.2869, 0.0196, 0.1265, 0.4460, 0.2904, 0.4743]),\n",
       "  tensor([4.9248e-01, 3.2627e-01, 3.0349e-01, 6.0767e-04, 6.8539e-01, 5.2193e-01]),\n",
       "  tensor([0.1412, 0.8722, 0.7867, 0.8790, 0.2798, 0.1149]),\n",
       "  tensor([0.4754, 0.3637, 0.7234, 0.7863, 0.5685, 0.8254]),\n",
       "  tensor([0.0062, 0.8412, 0.8382, 0.3699, 0.1547, 0.5254]),\n",
       "  tensor([0.9035, 0.0094, 0.9067, 0.8229, 0.9845, 0.7472])],\n",
       " [tensor([0.9030, 0.1505, 0.5034, 0.4106, 0.3040, 0.2303]),\n",
       "  tensor([0.9632, 0.6148, 0.9349, 0.0138, 0.9778, 0.8629]),\n",
       "  tensor([0.1904, 0.6257, 0.9402, 0.7634, 0.0953, 0.4600]),\n",
       "  tensor([0.8357, 0.2279, 0.9459, 0.4253, 0.0292, 0.7662]),\n",
       "  tensor([0.6991, 0.4273, 0.9817, 0.8426, 0.5975, 0.6964]),\n",
       "  tensor([0.3609, 0.0586, 0.4814, 0.5126, 0.3529, 0.5083])],\n",
       " [tensor([0.1713, 0.6223, 0.4513, 0.4632, 0.5577, 0.4460]),\n",
       "  tensor([0.6282, 0.8259, 0.0427, 0.6136, 0.6671, 0.4271]),\n",
       "  tensor([0.9628, 0.9683, 0.3105, 0.7383, 0.8407, 0.6086]),\n",
       "  tensor([0.9657, 0.6303, 0.5311, 0.9091, 0.5843, 0.3391]),\n",
       "  tensor([0.8587, 0.4638, 0.2035, 0.6633, 0.6496, 0.8490]),\n",
       "  tensor([0.2441, 0.1334, 0.6711, 0.1318, 0.5126, 0.4870])],\n",
       " [tensor([0.2478, 0.0085, 0.5248, 0.9021, 0.7361, 0.0111]),\n",
       "  tensor([0.5787, 0.6420, 0.2752, 0.0249, 0.3805, 0.1888]),\n",
       "  tensor([0.6740, 0.9983, 0.1017, 0.5007, 0.6134, 0.5624]),\n",
       "  tensor([0.5152, 0.4620, 0.5967, 0.1404, 0.2163, 0.7114]),\n",
       "  tensor([0.2883, 0.0253, 0.7597, 0.9138, 0.3671, 0.9580]),\n",
       "  tensor([0.5789, 0.5226, 0.5994, 0.9133, 0.2846, 0.1763])],\n",
       " [tensor([0.6071, 0.2622, 0.4516, 0.9773, 0.3208, 0.7172]),\n",
       "  tensor([0.0819, 0.9402, 0.7677, 0.3318, 0.3737, 0.6529]),\n",
       "  tensor([0.2138, 0.5603, 0.5888, 0.2838, 0.9457, 0.4037]),\n",
       "  tensor([0.8327, 0.9500, 0.0172, 0.4679, 0.7153, 0.8768]),\n",
       "  tensor([0.3002, 0.1265, 0.7470, 0.5462, 0.8274, 0.1149]),\n",
       "  tensor([0.5658, 0.7260, 0.6368, 0.5657, 0.0154, 0.6297])],\n",
       " [tensor([0.3220, 0.9842, 0.6733, 0.2283, 0.3414, 0.4019]),\n",
       "  tensor([0.0274, 0.9183, 0.3082, 0.1607, 0.8772, 0.8560]),\n",
       "  tensor([0.2832, 0.8702, 0.6694, 0.0685, 0.3797, 0.7964]),\n",
       "  tensor([0.0861, 0.2688, 0.5217, 0.4847, 0.0955, 0.7617]),\n",
       "  tensor([0.6282, 0.0159, 0.9551, 0.3957, 0.8291, 0.8349]),\n",
       "  tensor([0.5717, 0.7269, 0.5213, 0.8912, 0.5953, 0.1764])],\n",
       " [tensor([0.9431, 0.4618, 0.0998, 0.2881, 0.2831, 0.9303]),\n",
       "  tensor([0.9871, 0.0514, 0.9292, 0.1869, 0.9637, 0.8706]),\n",
       "  tensor([0.4728, 0.8676, 0.8844, 0.3168, 0.4005, 0.6185]),\n",
       "  tensor([0.0879, 0.1133, 0.7718, 0.9147, 0.8616, 0.8001]),\n",
       "  tensor([0.0958, 0.2687, 0.5859, 0.3186, 0.2157, 0.3681]),\n",
       "  tensor([0.5666, 0.8294, 0.8434, 0.5645, 0.4640, 0.7891])],\n",
       " [tensor([0.4491, 0.0345, 0.6444, 0.8035, 0.1718, 0.4730]),\n",
       "  tensor([0.4946, 0.7516, 0.4868, 0.3068, 0.6850, 0.1581]),\n",
       "  tensor([0.0705, 0.6895, 0.5757, 0.4398, 0.9241, 0.7176]),\n",
       "  tensor([0.1457, 0.8207, 0.1117, 0.4973, 0.1224, 0.9280]),\n",
       "  tensor([0.9510, 0.3493, 0.6833, 0.3888, 0.7177, 0.6601]),\n",
       "  tensor([0.3050, 0.9240, 0.3982, 0.4474, 0.1774, 0.7847])],\n",
       " tensor([[1., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 1., 1., 1.],\n",
       "         [1., 0., 1., 1., 1., 1.]], dtype=torch.float64),\n",
       " tensor([[1., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 1., 0., 0.],\n",
       "         [1., 0., 1., 1., 0., 0.]], dtype=torch.float64),\n",
       " tensor([[1., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 0., 0., 1., 0.]], dtype=torch.float64),\n",
       " tensor([[0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 1., 1., 1.]], dtype=torch.float64),\n",
       " tensor([[0., 0., 0., 0., 0., 1.],\n",
       "         [1., 0., 0., 0., 0., 1.]], dtype=torch.float64),\n",
       " tensor([[0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 1., 0., 0.]], dtype=torch.float64),\n",
       " tensor([[0., 0., 0., 0., 1., 0.],\n",
       "         [0., 1., 0., 1., 1., 0.],\n",
       "         [1., 1., 1., 1., 1., 1.]], dtype=torch.float64),\n",
       " tensor([[0., 0., 0., 0., 1., 0.]], dtype=torch.float64),\n",
       " tensor([[0., 0., 0., 0., 1., 0.],\n",
       "         [1., 0., 0., 0., 1., 0.],\n",
       "         [1., 1., 0., 1., 1., 0.],\n",
       "         [1., 1., 0., 1., 1., 1.]], dtype=torch.float64),\n",
       " tensor([[0., 0., 1., 0., 0., 0.],\n",
       "         [1., 0., 1., 1., 0., 1.],\n",
       "         [1., 1., 1., 1., 0., 1.],\n",
       "         [1., 1., 1., 1., 1., 1.]], dtype=torch.float64),\n",
       " tensor([[1., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 1., 1., 1.],\n",
       "         [1., 0., 1., 1., 1., 1.]], dtype=torch.float64),\n",
       " tensor([[1., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 1., 0., 0.],\n",
       "         [1., 0., 1., 1., 0., 0.]], dtype=torch.float64),\n",
       " tensor([[1., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 0., 0., 1., 0.]], dtype=torch.float64),\n",
       " tensor([[0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 1., 1., 1.]], dtype=torch.float64),\n",
       " tensor([[0., 0., 0., 0., 0., 1.],\n",
       "         [1., 0., 0., 0., 0., 1.]], dtype=torch.float64),\n",
       " tensor([[0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 1., 0., 0.]], dtype=torch.float64),\n",
       " tensor([[0., 0., 0., 0., 1., 0.],\n",
       "         [0., 1., 0., 1., 1., 0.],\n",
       "         [1., 1., 1., 1., 1., 1.]], dtype=torch.float64),\n",
       " tensor([[0., 0., 0., 0., 1., 0.]], dtype=torch.float64),\n",
       " tensor([[0., 0., 0., 0., 1., 0.],\n",
       "         [1., 0., 0., 0., 1., 0.],\n",
       "         [1., 1., 0., 1., 1., 0.],\n",
       "         [1., 1., 0., 1., 1., 1.]], dtype=torch.float64),\n",
       " tensor([[0., 0., 1., 0., 0., 0.],\n",
       "         [1., 0., 1., 1., 0., 1.],\n",
       "         [1., 1., 1., 1., 0., 1.],\n",
       "         [1., 1., 1., 1., 1., 1.]], dtype=torch.float64),\n",
       " tensor([[1., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 1., 1., 1.],\n",
       "         [1., 0., 1., 1., 1., 1.]], dtype=torch.float64),\n",
       " tensor([[1., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 1., 0., 0.],\n",
       "         [1., 0., 1., 1., 0., 0.]], dtype=torch.float64),\n",
       " tensor([[1., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 0., 0., 1., 0.]], dtype=torch.float64),\n",
       " tensor([[0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 1., 1., 1.]], dtype=torch.float64),\n",
       " tensor([[0., 0., 0., 0., 0., 1.],\n",
       "         [1., 0., 0., 0., 0., 1.]], dtype=torch.float64),\n",
       " tensor([[0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 1., 0., 0.]], dtype=torch.float64),\n",
       " tensor([[0., 0., 0., 0., 1., 0.],\n",
       "         [0., 1., 0., 1., 1., 0.],\n",
       "         [1., 1., 1., 1., 1., 1.]], dtype=torch.float64),\n",
       " tensor([[0., 0., 0., 0., 1., 0.]], dtype=torch.float64),\n",
       " tensor([[0., 0., 0., 0., 1., 0.],\n",
       "         [1., 0., 0., 0., 1., 0.],\n",
       "         [1., 1., 0., 1., 1., 0.],\n",
       "         [1., 1., 0., 1., 1., 1.]], dtype=torch.float64),\n",
       " tensor([[0., 0., 1., 0., 0., 0.],\n",
       "         [1., 0., 1., 1., 0., 1.],\n",
       "         [1., 1., 1., 1., 0., 1.],\n",
       "         [1., 1., 1., 1., 1., 1.]], dtype=torch.float64)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 1., 1., 1., 0.], dtype=torch.float64)\n",
      "tensor([1., 0., 1., 1., 1., 0.], dtype=torch.float64)\n",
      "tensor(0., dtype=torch.float64)\n",
      "tensor([1., 1., 0., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([1., 1., 0., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor(0., dtype=torch.float64)\n",
      "tensor([1., 0., 1., 0., 1., 1.], dtype=torch.float64)\n",
      "tensor([1., 0., 1., 0., 1., 1.], dtype=torch.float64)\n",
      "tensor(0., dtype=torch.float64)\n",
      "tensor([1., 0., 0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([1., 0., 0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor(0., dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1., 1., 0.], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1., 1., 0.], dtype=torch.float64)\n",
      "tensor(0., dtype=torch.float64)\n",
      "tensor([1., 0., 0., 0., 1., 0.], dtype=torch.float64)\n",
      "tensor([1., 0., 0., 0., 1., 0.], dtype=torch.float64)\n",
      "tensor(0., dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor(0., dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor(0., dtype=torch.float64)\n",
      "tensor([1., 0., 1., 1., 0., 1.], dtype=torch.float64)\n",
      "tensor([1., 0., 1., 1., 0., 1.], dtype=torch.float64)\n",
      "tensor(0., dtype=torch.float64)\n",
      "tensor([1., 0., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([1., 0., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor(0., dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(nan, dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test loss on \n",
    "batch = dataset\n",
    "batch_pred = predictions\n",
    "\n",
    "loss = Loss()\n",
    "loss(batch, batch_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1.reach_h[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = d1['reach_h'][-1]\n",
    "x_pred = torch.rand_like(x)\n",
    "h = d1.reach_h[:-2]\n",
    "h_pred = torch.rand_like(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13.5479, dtype=torch.float64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = Loss()\n",
    "loss(x, x_pred, h, h_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = nx.read_edgelist(\"./data/raw/er_graph_0.edgelist\")\n",
    "# create the adjacency matrix knowing that there are n nodes and n = 6\n",
    "n=6\n",
    "\n",
    "adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.read_edgelist(\"./data/raw/er_graph_0.edgelist\")\n",
    "edges_indexes = self.get_edges_indexes(adj)\n",
    "s = np.random.randint(0, len(adj))\n",
    "pi, probes = bfs(adj, s)\n",
    "pi_h = probes['hint']['node']['pi_h']['data']\n",
    "reach_h = probes['hint']['node']['reach_h']['data']\n",
    "pi = self.get_edges(adj, pi)\n",
    "pi_h = np.array([self.get_edges(adj, x) for x in pi_h])\n",
    "pos = np.arange(0, len(adj))/len(adj)\n",
    "length = (pi_h).shape[0]\n",
    "dict = {'edge_index': edges_indexes, 'pos': pos, 'length': length, 's': s, 'pi': pi, 'reach_h': reach_h, 'pi_h': pi_h}\n",
    "dict = {k: self.to_torch(v) for k,v in dict.items()}\n",
    "dict['hints'] = np.array(['reach_h', 'pi_h'])\n",
    "dict['inputs'] = np.array(['pos', 's'])\n",
    "dict['outputs'] = np.array(['pi'])\n",
    "tensor = CLRSData(**dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
