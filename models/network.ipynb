{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import generator from '../data/generator.py'\n",
    "import sys\n",
    "import os\n",
    "from generator import RandomGraphDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from encoder import Encoder\n",
    "from decoder import Decoder\n",
    "from mpnn import MPNN\n",
    "from torch.functional import F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        super(Network, self).__init__()\n",
    "        self.encoder = Encoder(2, latent_dim)\n",
    "        self.processor = MPNN(latent_dim*2, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, 1)\n",
    "\n",
    "    def forward(self, batch, max_iter=10):\n",
    "        input = torch.stack((batch.pos, batch.s), dim=1).float()\n",
    "        h = torch.zeros(input.size(0), 128) # hidden state from the processor\n",
    "        hints_edges = batch.edges_h[1:] # hints if an edge was passed or not\n",
    "        true_output = batch.edges # true_output for all the edges if they were passed or not at the end.\n",
    "        max_iter = hints_edges.size(0)\n",
    "\n",
    "        hints_reach = batch.reach_h[1:] # hints from the reachability\n",
    "        \n",
    "        predictions_edges = torch.zeros(max_iter, batch.edges.size(0))\n",
    "        predictions_reach = torch.zeros(max_iter, batch.s.size(0))\n",
    "\n",
    "        for i in range(max_iter):\n",
    "            threshold = 0.\n",
    "\n",
    "            # NETWORK START\n",
    "            z = self.encoder(input) # the encoded input\n",
    "            processor_input = torch.cat([z, h], dim=1) # the input to the processor\n",
    "            h = self.processor(processor_input, batch.edge_index.long()) # the output of the processor\n",
    "            decoder_input = torch.cat((h[batch.edge_index[0]], h[batch.edge_index[1]]), dim=1)\n",
    "            alpha = self.decoder(decoder_input).view(batch.edges.size(0))\n",
    "            # NETWORK END\n",
    "\n",
    "            # predictions for the edges\n",
    "            predictions_edges[i] = alpha.view(batch.edges.size(0))\n",
    "            # update the input with the new state\n",
    "            input = torch.stack((batch.pos, predictions_reach[i]), dim=1).float()\n",
    "\n",
    "        # predictions for reach \n",
    "        predictions_reach = self.calculate_reach(batch, alpha, threshold=threshold)\n",
    "\n",
    "        # predictions for the parents\n",
    "        predictions_parents = self.get_parent_nodes(batch.edge_index, alpha, batch.s, threshold=threshold)\n",
    "        \n",
    "        loss_edges = self.calculate_loss(hints_edges, predictions_edges, true_output)\n",
    "        loss_reach = self.calculate_reach_loss(predictions_reach, batch.reach_h[-1])\n",
    "        loss_parents = self.calculate_parents_loss(predictions_parents, batch.pi)\n",
    "        \n",
    "        return loss_edges, loss_reach, loss_parents\n",
    "        \n",
    "    def calculate_loss(self, hints, predictions, true_output):\n",
    "        if len(predictions) == 0:\n",
    "            return torch.tensor(0.0), torch.tensor(0.0)  # Return zero loss if predictions is empty\n",
    "        loss_x = F.binary_cross_entropy(predictions[-1], true_output.type(torch.float))\n",
    "        loss_h = 0\n",
    "        for i in range(hints.size(0)):\n",
    "            loss_h += F.binary_cross_entropy(predictions[i], hints[i].type(torch.float))\n",
    "        return loss_x, loss_h\n",
    "    \n",
    "    def calculate_reach_loss(self, predictions, true_output):\n",
    "        return  F.binary_cross_entropy(predictions, true_output.type(torch.float))\n",
    "    \n",
    "\n",
    "    def calculate_reach(self, graph, alpha, threshold=0.8):\n",
    "        \"\"\"\n",
    "        Calculate reachability values for each node from the alpha values\n",
    "\n",
    "        Args:\n",
    "        - graph: Graph object containing graph data\n",
    "        - alpha: PyTorch tensor containing alpha values\n",
    "        - threshold: Threshold value for reachability\n",
    "\n",
    "        Returns:\n",
    "        - y: PyTorch tensor containing reachability values for each node\n",
    "        \"\"\"\n",
    "        y = torch.zeros((len(graph.s)))\n",
    "        for node_index in range(len(graph.s)):\n",
    "            # Check if there are any edges connected to the current node\n",
    "            connected_edges = torch.logical_or(graph.edge_index[0] == node_index, graph.edge_index[1] == node_index)\n",
    "            if torch.any(connected_edges):\n",
    "                alpha_max_proba = alpha[connected_edges].max()\n",
    "                if alpha_max_proba.item() >= threshold:\n",
    "                    y[node_index] = 1\n",
    "        return y\n",
    "\n",
    "\n",
    "    def get_parent_nodes(self, edge_index, alpha, s, threshold=0.8):\n",
    "        num_nodes = len(s)\n",
    "        parent_nodes = torch.arange(num_nodes)  # Initialize parent nodes with their own index\n",
    "\n",
    "        for node in range(num_nodes):\n",
    "            # Get all edges that point to the current node\n",
    "            incoming_edges = (edge_index[1] == node).nonzero(as_tuple=False).squeeze()\n",
    "            \n",
    "            # Check if there are any edges pointing to the current node\n",
    "            if incoming_edges.numel() != 0:\n",
    "                # Filter alpha based on threshold\n",
    "                filtered_edges = incoming_edges[alpha[incoming_edges] >= threshold]\n",
    "                \n",
    "                # Check if there are any edges left after filtering\n",
    "                if filtered_edges.numel() != 0:\n",
    "                    # Get the index of the edge with the highest alpha after filtering\n",
    "                    max_alpha_index = torch.argmax(alpha[filtered_edges])\n",
    "                    # Get the parent node\n",
    "                    parent_nodes[node] = edge_index[0, filtered_edges[max_alpha_index]].item()\n",
    "\n",
    "        return parent_nodes\n",
    "\n",
    "    def calculate_parents_loss(self, predictions_parents, final_parents):\n",
    "        if len(predictions_parents) == 0 or len(final_parents) == 0:\n",
    "            return torch.tensor(1.0) \n",
    "        return 1 - torch.mean(torch.eq(predictions_parents, final_parents).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from encoder import Encoder\n",
    "from decoder import Decoder\n",
    "from mpnn import MPNN\n",
    "from torch.functional import F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        super(Network, self).__init__()\n",
    "        self.encoder = Encoder(2, latent_dim)\n",
    "        self.processor = MPNN(latent_dim*2, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, 1)\n",
    "\n",
    "    def forward(self, batch, max_iter=10):\n",
    "        input = torch.stack((batch.pos, batch.s), dim=1).float()\n",
    "        h = torch.zeros(input.size(0), 128) # hidden state from the processor\n",
    "        hints_edges = batch.edges_h[1:] # hints if an edge was passed or not\n",
    "        true_output = batch.edges # true_output for all the edges if they were passed or not at the end.\n",
    "        max_iter = hints_edges.size(0)\n",
    "\n",
    "        hints_reach = batch.reach_h[1:] # hints from the reachability\n",
    "        \n",
    "        predictions_edges = torch.zeros(max_iter, batch.edges.size(0))\n",
    "\n",
    "        for i in range(max_iter):\n",
    "            threshold = 0.5\n",
    "\n",
    "            # NETWORK START\n",
    "            z = self.encoder(input) # the encoded input\n",
    "            processor_input = torch.cat([z, h], dim=1) # the input to the processor\n",
    "            h = self.processor(processor_input, batch.edge_index.long()) # the output of the processor\n",
    "            decoder_input = torch.cat((h[batch.edge_index[0]], h[batch.edge_index[1]]), dim=1)\n",
    "            alpha = self.decoder(decoder_input).view(batch.edges.size(0))\n",
    "            # NETWORK END\n",
    "\n",
    "            # predictions for the edges\n",
    "            predictions_edges[i] = alpha.view(batch.edges.size(0))\n",
    "            # update the input with the new state\n",
    "            predictions_reach = self.calculate_reach(batch, alpha, threshold=0.4)\n",
    "            \n",
    "            input = torch.stack((batch.pos, predictions_reach), dim=1).float()\n",
    "\n",
    "        # predictions for reach \n",
    "\n",
    "        # predictions for the parents\n",
    "        predictions_parents = self.get_parent_nodes(batch.edge_index, alpha, batch.s, threshold=0.)\n",
    "        \n",
    "        loss_edges = self.calculate_loss(hints_edges, predictions_edges, true_output)\n",
    "        loss_reach = self.calculate_reach_loss(predictions_reach, batch.reach_h[-1])\n",
    "        loss_parents = self.calculate_parents_loss(predictions_parents, batch.pi)\n",
    "        \n",
    "        return loss_edges, loss_reach, loss_parents\n",
    "        \n",
    "    def calculate_loss(self, hints, predictions, true_output):\n",
    "        if len(predictions) == 0:\n",
    "            return torch.tensor(0.0), torch.tensor(0.0)  # Return zero loss if predictions is empty\n",
    "        loss_x = F.binary_cross_entropy(predictions[-1], true_output.type(torch.float))\n",
    "        loss_h = 0\n",
    "        for i in range(hints.size(0)):\n",
    "            loss_h += F.binary_cross_entropy(predictions[i], hints[i].type(torch.float))\n",
    "        return loss_x, loss_h\n",
    "    \n",
    "    def calculate_reach_loss(self, predictions, true_output):\n",
    "        return F.binary_cross_entropy(predictions, true_output.type(torch.float))\n",
    "    \n",
    "\n",
    "    def calculate_reach(self, graph, alpha, threshold=0.8):\n",
    "        \"\"\"\n",
    "        Calculate reachability values for each node from the alpha values\n",
    "\n",
    "        Args:\n",
    "        - graph: Graph object containing graph data\n",
    "        - alpha: PyTorch tensor containing alpha values\n",
    "        - threshold: Threshold value for reachability\n",
    "\n",
    "        Returns:\n",
    "        - y: PyTorch tensor containing reachability values for each node\n",
    "        \"\"\"\n",
    "        y = torch.zeros((len(graph.s)))\n",
    "        for node_index in range(len(graph.s)):\n",
    "            # Check if there are any edges connected to the current node\n",
    "            connected_edges = torch.logical_or(graph.edge_index[0] == node_index, graph.edge_index[1] == node_index)\n",
    "            if torch.any(connected_edges):\n",
    "                alpha_max_proba = alpha[connected_edges].max()\n",
    "                if alpha_max_proba.item() >= threshold:\n",
    "                    y[node_index] = 1\n",
    "        return y\n",
    "\n",
    "\n",
    "    def get_parent_nodes(self, edge_index, alpha, s, threshold=0.8):\n",
    "        num_nodes = len(s)\n",
    "        parent_nodes = torch.arange(num_nodes)  # Initialize parent nodes with their own index\n",
    "\n",
    "        for node in range(num_nodes):\n",
    "            # Get all edges that point to the current node\n",
    "            incoming_edges = (edge_index[1] == node).nonzero(as_tuple=False).squeeze()\n",
    "            \n",
    "            # Check if there are any edges pointing to the current node\n",
    "            if incoming_edges.numel() != 0:\n",
    "                # Filter alpha based on threshold\n",
    "                filtered_edges = incoming_edges[alpha[incoming_edges] >= threshold]\n",
    "                \n",
    "                # Check if there are any edges left after filtering\n",
    "                if filtered_edges.numel() != 0:\n",
    "                    # Get the index of the edge with the highest alpha after filtering\n",
    "                    max_alpha_index = torch.argmax(alpha[filtered_edges])\n",
    "                    # Get the parent node\n",
    "                    parent_nodes[node] = edge_index[0, filtered_edges[max_alpha_index]].item()\n",
    "\n",
    "        return parent_nodes\n",
    "\n",
    "    def calculate_parents_loss(self, predictions_parents, final_parents):\n",
    "        if len(predictions_parents) == 0 or len(final_parents) == 0:\n",
    "            return torch.tensor(1.0) \n",
    "        return 1 - torch.mean(torch.eq(predictions_parents, final_parents).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataset, validation_dataset=None, optimizer=None, epochs=10, batch_size=5):\n",
    "    x_loss_weight = 0.5\n",
    "    h_loss_weight = 1 - x_loss_weight\n",
    "\n",
    "    loss_edges_train, loss_reach_train, loss_parents_train = [], [], []\n",
    "    loss_edges_val, loss_reach_val, loss_parents_val = [], [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        batch_count = len(train_dataset) // batch_size\n",
    "        \n",
    "        cumulated_loss_edges_epoch, cumulated_loss_reach_epoch, cumulated_loss_parents_epoch = 0, 0, 0\n",
    "\n",
    "        for i in range(batch_count):\n",
    "            model.train()\n",
    "            cumulated_loss_edges, cumulated_loss_reach, cumulated_loss_parents = 0, 0, 0\n",
    "            for j in range(i*batch_size, (i+1)*batch_size):\n",
    "                graph = train_dataset[j] \n",
    "                loss_edges, loss_reach, loss_parents = model(graph)\n",
    "                loss_edges_output, loss_edges_hints = loss_edges[0], loss_edges[1] # loss for the edges\n",
    "\n",
    "                cumulated_loss_edges += x_loss_weight * loss_edges_output + h_loss_weight * loss_edges_hints\n",
    "                cumulated_loss_reach += loss_reach\n",
    "                cumulated_loss_parents += loss_parents\n",
    "\n",
    "            cumulated_loss_edges /= batch_size\n",
    "            cumulated_loss_reach /= batch_size\n",
    "            cumulated_loss_parents /= batch_size\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            cumulated_loss_edges.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            cumulated_loss_edges_epoch += cumulated_loss_edges\n",
    "            cumulated_loss_reach_epoch += cumulated_loss_reach\n",
    "            cumulated_loss_parents_epoch += cumulated_loss_parents\n",
    "\n",
    "        # Convert tensors to lists and append to the respective lists\n",
    "        loss_edges_train.append(cumulated_loss_edges_epoch.item() / batch_count)\n",
    "        loss_reach_train.append(cumulated_loss_reach_epoch.item() / batch_count)\n",
    "        loss_parents_train.append(cumulated_loss_parents_epoch.item() / batch_count)\n",
    "\n",
    "        if validation_dataset:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                cumulated_loss_edges_val, cumulated_loss_reach_val, cumulated_loss_parents_val = 0, 0, 0\n",
    "                for k in range(len(validation_dataset)):\n",
    "                    graph = validation_dataset[k]\n",
    "                    loss_edges, loss_reach, loss_parents = model(graph)\n",
    "                    loss_edges_output, loss_edges_hints = loss_edges[0], loss_edges[1] # loss for the edges\n",
    "\n",
    "                    cumulated_loss_edges_val += x_loss_weight * loss_edges_output + h_loss_weight * loss_edges_hints\n",
    "                    cumulated_loss_reach_val += loss_reach\n",
    "                    cumulated_loss_parents_val += loss_parents \n",
    "\n",
    "                cumulated_loss_edges_val /= len(validation_dataset)\n",
    "                cumulated_loss_reach_val /= len(validation_dataset)\n",
    "                cumulated_loss_parents_val /= len(validation_dataset)\n",
    "\n",
    "                loss_edges_val.append(cumulated_loss_edges_val.item())\n",
    "                loss_reach_val.append(cumulated_loss_reach_val.item())\n",
    "                loss_parents_val.append(cumulated_loss_parents_val.item())\n",
    "\n",
    "                print(f'Epoch {epoch}, loss_edges {cumulated_loss_edges_epoch.item() / batch_count}, loss_reach {cumulated_loss_reach_epoch.item() / batch_count}, loss_parents {cumulated_loss_parents_epoch.item() / batch_count}, loss_edges_val {cumulated_loss_edges_val.item()}, loss_reach_val {cumulated_loss_reach_val.item()}, loss_parents_val {cumulated_loss_parents_val.item()}')\n",
    "        \n",
    "        else:\n",
    "            print(f'Epoch {epoch}, loss_edges {cumulated_loss_edges_epoch.item() / batch_count}, loss_reach {cumulated_loss_reach_epoch.item() / batch_count}, loss_parents {cumulated_loss_parents_epoch.item() / batch_count}')\n",
    "\n",
    "    if validation_dataset:\n",
    "        return loss_edges_train, loss_reach_train, loss_parents_train, loss_edges_val, loss_reach_val, loss_parents_val\n",
    "    return loss_edges_train, loss_reach_train, loss_parents_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and testing using the train_test_split function\n",
    "from torch.utils.data import random_split\n",
    "n=[20, 100]\n",
    "p=0.3\n",
    "dataset = RandomGraphDataset(root='./data/medium', gen_num_graph=400, n=n, p=p)\n",
    "train_dataset, test_dataset = random_split(dataset, [350, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss_edges 0.9051346778869629, loss_reach 42.8125, loss_parents 0.9152854919433594\n",
      "Epoch 1, loss_edges 0.5857968807220459, loss_reach 100.0, loss_parents 0.8991043090820312\n",
      "Epoch 2, loss_edges 0.4009081363677979, loss_reach 100.0, loss_parents 0.9104509353637695\n",
      "Epoch 3, loss_edges 0.37909085750579835, loss_reach 100.0, loss_parents 0.8675930023193359\n",
      "Epoch 4, loss_edges 0.35494070053100585, loss_reach 100.0, loss_parents 0.7881206512451172\n",
      "Epoch 5, loss_edges 0.3445765733718872, loss_reach 100.0, loss_parents 0.746375036239624\n",
      "Epoch 6, loss_edges 0.33559494018554686, loss_reach 100.0, loss_parents 0.7200651645660401\n",
      "Epoch 7, loss_edges 0.3304239511489868, loss_reach 100.0, loss_parents 0.6848750591278077\n",
      "Epoch 8, loss_edges 0.32790484428405764, loss_reach 100.0, loss_parents 0.6754697322845459\n",
      "Epoch 9, loss_edges 0.3249059677124023, loss_reach 100.0, loss_parents 0.6750641822814941\n",
      "Epoch 10, loss_edges 0.3218754768371582, loss_reach 100.0, loss_parents 0.6769544601440429\n",
      "Epoch 11, loss_edges 0.3189030408859253, loss_reach 100.0, loss_parents 0.672144079208374\n",
      "Epoch 12, loss_edges 0.3154716491699219, loss_reach 100.0, loss_parents 0.6626269817352295\n",
      "Epoch 13, loss_edges 0.31016685962677004, loss_reach 100.0, loss_parents 0.6434929370880127\n",
      "Epoch 14, loss_edges 0.301543664932251, loss_reach 100.0, loss_parents 0.6102519512176514\n",
      "Epoch 15, loss_edges 0.2851488351821899, loss_reach 100.0, loss_parents 0.5297501564025879\n",
      "Epoch 16, loss_edges 0.24837963581085204, loss_reach 91.8992431640625, loss_parents 0.3478950023651123\n",
      "Epoch 17, loss_edges 0.19308460950851442, loss_reach 61.98409423828125, loss_parents 0.142891788482666\n",
      "Epoch 18, loss_edges 0.18820393085479736, loss_reach 44.52072448730469, loss_parents 0.0773622751235962\n",
      "Epoch 19, loss_edges 0.16269242763519287, loss_reach 43.879696655273435, loss_parents 0.11868641376495362\n",
      "Epoch 20, loss_edges 0.1482228994369507, loss_reach 39.814019775390626, loss_parents 0.1209132194519043\n",
      "Epoch 21, loss_edges 0.1321794033050537, loss_reach 39.2862548828125, loss_parents 0.08698465824127197\n",
      "Epoch 22, loss_edges 0.11468693017959594, loss_reach 33.25791015625, loss_parents 0.0531730592250824\n",
      "Epoch 23, loss_edges 0.10432770252227783, loss_reach 24.972854614257812, loss_parents 0.049823459982872007\n",
      "Epoch 24, loss_edges 0.09722949266433716, loss_reach 22.5478271484375, loss_parents 0.03237442374229431\n",
      "Epoch 25, loss_edges 0.09340827465057373, loss_reach 22.423237609863282, loss_parents 0.02923303246498108\n",
      "Epoch 26, loss_edges 0.0892987847328186, loss_reach 21.632464599609374, loss_parents 0.028791019320487977\n",
      "Epoch 27, loss_edges 0.08486486673355102, loss_reach 19.206358337402342, loss_parents 0.029251757264137267\n",
      "Epoch 28, loss_edges 0.08067768812179565, loss_reach 16.759873962402345, loss_parents 0.0292748898267746\n",
      "Epoch 29, loss_edges 0.07737519145011902, loss_reach 15.631602478027343, loss_parents 0.029737105965614317\n",
      "Epoch 30, loss_edges 0.07457717657089233, loss_reach 14.689401245117187, loss_parents 0.02947244942188263\n",
      "Epoch 31, loss_edges 0.07230393290519714, loss_reach 14.244523620605468, loss_parents 0.029404661059379576\n",
      "Epoch 32, loss_edges 0.0703730046749115, loss_reach 14.333610534667969, loss_parents 0.029472893476486205\n",
      "Epoch 33, loss_edges 0.06864717602729797, loss_reach 14.144557189941406, loss_parents 0.029669177532196046\n",
      "Epoch 34, loss_edges 0.06711706519126892, loss_reach 13.822348022460938, loss_parents 0.029466041922569276\n",
      "Epoch 35, loss_edges 0.06578031778335572, loss_reach 13.426441955566407, loss_parents 0.029250383377075195\n",
      "Epoch 36, loss_edges 0.06457395553588867, loss_reach 13.060357666015625, loss_parents 0.02890098690986633\n",
      "Epoch 37, loss_edges 0.06273882389068604, loss_reach 12.496582794189454, loss_parents 0.028504106402397155\n",
      "Epoch 38, loss_edges 0.06109035611152649, loss_reach 11.72021255493164, loss_parents 0.02798505425453186\n",
      "Epoch 39, loss_edges 0.05946283340454102, loss_reach 11.141322326660156, loss_parents 0.027548950910568238\n",
      "Epoch 40, loss_edges 0.0576817512512207, loss_reach 10.586557006835937, loss_parents 0.02722695767879486\n",
      "Epoch 41, loss_edges 0.05598905086517334, loss_reach 9.815296936035157, loss_parents 0.02690470814704895\n",
      "Epoch 42, loss_edges 0.0545670211315155, loss_reach 9.146597290039063, loss_parents 0.02679397463798523\n",
      "Epoch 43, loss_edges 0.053052347898483274, loss_reach 8.388157653808594, loss_parents 0.02614627480506897\n",
      "Epoch 44, loss_edges 0.05177883505821228, loss_reach 7.974437713623047, loss_parents 0.02574194073677063\n",
      "Epoch 45, loss_edges 0.05068674683570862, loss_reach 7.570902252197266, loss_parents 0.025895026326179505\n",
      "Epoch 46, loss_edges 0.04954066872596741, loss_reach 7.1317695617675785, loss_parents 0.025763878226280214\n",
      "Epoch 47, loss_edges 0.04826783835887909, loss_reach 6.612631988525391, loss_parents 0.02554955780506134\n",
      "Epoch 48, loss_edges 0.047194427251815795, loss_reach 6.062517929077148, loss_parents 0.025585055351257324\n",
      "Epoch 49, loss_edges 0.046279770135879514, loss_reach 5.745465469360352, loss_parents 0.025409218668937684\n",
      "Epoch 50, loss_edges 0.04508824348449707, loss_reach 5.300143814086914, loss_parents 0.025527691841125487\n",
      "Epoch 51, loss_edges 0.04391722977161407, loss_reach 4.4784294128417965, loss_parents 0.025422883033752442\n",
      "Epoch 52, loss_edges 0.042752063274383544, loss_reach 4.105400848388672, loss_parents 0.025221773982048036\n",
      "Epoch 53, loss_edges 0.04143989682197571, loss_reach 3.436594772338867, loss_parents 0.024917566776275636\n",
      "Epoch 54, loss_edges 0.04014890491962433, loss_reach 2.8072256088256835, loss_parents 0.024917566776275636\n",
      "Epoch 55, loss_edges 0.038837972283363345, loss_reach 2.0119112014770506, loss_parents 0.024743038415908813\n",
      "Epoch 56, loss_edges 0.037512728571891786, loss_reach 1.7020624160766602, loss_parents 0.02480526566505432\n",
      "Epoch 57, loss_edges 0.036226975917816165, loss_reach 1.2172127723693849, loss_parents 0.0246562659740448\n",
      "Epoch 58, loss_edges 0.034842652082443235, loss_reach 0.9574240684509278, loss_parents 0.024540525674819947\n",
      "Epoch 59, loss_edges 0.03347640335559845, loss_reach 0.7515550136566163, loss_parents 0.024272668361663818\n",
      "Epoch 60, loss_edges 0.032116633653640744, loss_reach 0.6447131633758545, loss_parents 0.02349834591150284\n",
      "Epoch 61, loss_edges 0.030886772274971008, loss_reach 0.5578216075897217, loss_parents 0.023249274492263793\n",
      "Epoch 62, loss_edges 0.029919785261154175, loss_reach 0.5060091972351074, loss_parents 0.023078471422195435\n",
      "Epoch 63, loss_edges 0.02897646129131317, loss_reach 0.49375362396240235, loss_parents 0.022959762811660768\n",
      "Epoch 64, loss_edges 0.02808256447315216, loss_reach 0.44301614761352537, loss_parents 0.022715958952903747\n",
      "Epoch 65, loss_edges 0.027315932512283325, loss_reach 0.4184861183166504, loss_parents 0.022715958952903747\n",
      "Epoch 66, loss_edges 0.026607403159141542, loss_reach 0.4214622974395752, loss_parents 0.022602537274360658\n",
      "Epoch 67, loss_edges 0.025970682501792908, loss_reach 0.4433292388916016, loss_parents 0.02244628667831421\n",
      "Epoch 68, loss_edges 0.025270220637321473, loss_reach 0.4055938720703125, loss_parents 0.022130629420280455\n",
      "Epoch 69, loss_edges 0.02470923215150833, loss_reach 0.39563963413238523, loss_parents 0.022130629420280455\n",
      "Epoch 70, loss_edges 0.024165070056915282, loss_reach 0.38104822635650637, loss_parents 0.02192363142967224\n",
      "Epoch 71, loss_edges 0.023693832755088805, loss_reach 0.3253357410430908, loss_parents 0.021803438663482666\n",
      "Epoch 72, loss_edges 0.023153993487358093, loss_reach 0.31482486724853515, loss_parents 0.021586695313453676\n",
      "Epoch 73, loss_edges 0.022735755145549773, loss_reach 0.31224751472473145, loss_parents 0.021478936076164246\n",
      "Epoch 74, loss_edges 0.022303248941898345, loss_reach 0.2836016654968262, loss_parents 0.021330755949020386\n",
      "Epoch 75, loss_edges 0.021851631999015807, loss_reach 0.28040566444396975, loss_parents 0.02120629996061325\n",
      "Epoch 76, loss_edges 0.02141919285058975, loss_reach 0.24893980026245116, loss_parents 0.02114429622888565\n",
      "Epoch 77, loss_edges 0.020967255532741546, loss_reach 0.24893980026245116, loss_parents 0.021066172420978545\n",
      "Epoch 78, loss_edges 0.02055385261774063, loss_reach 0.23461687564849854, loss_parents 0.020974260568618775\n",
      "Epoch 79, loss_edges 0.020090588927268983, loss_reach 0.19836145639419556, loss_parents 0.020887453854084016\n",
      "Epoch 80, loss_edges 0.019684091210365295, loss_reach 0.18157904148101806, loss_parents 0.020795542001724242\n",
      "Epoch 81, loss_edges 0.019263960421085358, loss_reach 0.17079036235809325, loss_parents 0.020795542001724242\n",
      "Epoch 82, loss_edges 0.018880882859230043, loss_reach 0.19769054651260376, loss_parents 0.020795542001724242\n",
      "Epoch 83, loss_edges 0.018524447083473207, loss_reach 0.2146942138671875, loss_parents 0.020595870912075043\n",
      "Epoch 84, loss_edges 0.01815863847732544, loss_reach 0.20762577056884765, loss_parents 0.020595870912075043\n",
      "Epoch 85, loss_edges 0.017721664905548096, loss_reach 0.20989391803741456, loss_parents 0.020595870912075043\n",
      "Epoch 86, loss_edges 0.0173206090927124, loss_reach 0.17958401441574096, loss_parents 0.020595870912075043\n",
      "Epoch 87, loss_edges 0.01693549007177353, loss_reach 0.15216367244720458, loss_parents 0.020595870912075043\n",
      "Epoch 88, loss_edges 0.016560357809066773, loss_reach 0.16293952465057374, loss_parents 0.020595870912075043\n",
      "Epoch 89, loss_edges 0.016217923164367674, loss_reach 0.14873499870300294, loss_parents 0.020595870912075043\n",
      "Epoch 90, loss_edges 0.01584230810403824, loss_reach 0.12779922485351564, loss_parents 0.020595870912075043\n",
      "Epoch 91, loss_edges 0.015462177991867065, loss_reach 0.1155510663986206, loss_parents 0.020595870912075043\n",
      "Epoch 92, loss_edges 0.015155547857284546, loss_reach 0.10368012189865113, loss_parents 0.020595870912075043\n",
      "Epoch 93, loss_edges 0.014835982024669648, loss_reach 0.10368012189865113, loss_parents 0.020595870912075043\n",
      "Epoch 94, loss_edges 0.01448930948972702, loss_reach 0.10368012189865113, loss_parents 0.020595870912075043\n",
      "Epoch 95, loss_edges 0.014137175679206849, loss_reach 0.08405604362487792, loss_parents 0.020595870912075043\n",
      "Epoch 96, loss_edges 0.01386292427778244, loss_reach 0.098228919506073, loss_parents 0.020595870912075043\n",
      "Epoch 97, loss_edges 0.013628719747066498, loss_reach 0.10980299711227418, loss_parents 0.020595870912075043\n",
      "Epoch 98, loss_edges 0.013456761837005615, loss_reach 0.12877179384231568, loss_parents 0.020454619824886323\n",
      "Epoch 99, loss_edges 0.013473716378211976, loss_reach 0.1380086660385132, loss_parents 0.020454619824886323\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam\n",
    "model = Network()\n",
    "lr = 0.0002\n",
    "\n",
    "loss_edges_train, loss_reach_train, loss_parents_train = train(model=model, train_dataset=train_dataset,\n",
    "      optimizer=optimizer(model.parameters(), lr=lr), epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam\n",
    "model = Network()\n",
    "lr = 0.0002\n",
    "\n",
    "loss_edges_train, loss_reach_train, loss_parents_train = train(model=model, train_dataset=train_dataset,\n",
    "      optimizer=optimizer(model.parameters(), lr=lr), epochs=80, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam\n",
    "model = Network()\n",
    "lr = 0.0001\n",
    "\n",
    "loss_edges_train, loss_reach_train, loss_parents_train, loss_edges_val, loss_reach_val, loss_parents_val = train(model=model, train_dataset=train_dataset, validation_dataset=test_dataset,\n",
    "      optimizer=optimizer(model.parameters(), lr=lr), epochs=200, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the losses\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_parents_val, label='val')\n",
    "plt.plot(loss_edges_train, label='train')\n",
    "\n",
    "plt.legend()\n",
    "# use log scale\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the losses\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_edges_val, label='val')\n",
    "plt.plot(loss_edges_train, label='train')\n",
    "\n",
    "plt.legend()\n",
    "# use log scale\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the losses\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_reach_val, label='val')\n",
    "plt.plot(loss_reach_train, label='train')\n",
    "\n",
    "plt.legend()\n",
    "# use log scale\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the losses\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_parents_val, label='train')\n",
    "plt.plot(loss_reach_val, label='train')\n",
    "plt.plot(loss_edges_val, label='train')\n",
    "plt.legend()\n",
    "# use log scale\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the losses\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_edges_train, label='train')\n",
    "plt.legend()\n",
    "# use log scale\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
